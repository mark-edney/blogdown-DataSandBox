solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, verbose = 3, n_jobs = 2)
grid.fit(X_train, y_train)
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
features = X_train.shape[1]
parameters = {'hidden_layer_sizes':[(1),(features),
(features,features), (features,features,features),
(features,features,features,features),
(features,features,features,features,features)]}
model = MLPClassifier(random_state = 1,max_iter = 1000,
solver = 'adam', learning_rate = 'adaptive', tol = 1e-6)
grid = GridSearchCV(estimator = model, param_grid = parameters, verbose = 3)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
features = X_train.shape[1]
parameters = {'hidden_layer_sizes':[(1),(features),
(features,features), (features,features,features),
(features,features,features,features),
(features,features,features,features,features)]}
model = MLPClassifier(random_state = 1,max_iter = 1000,
solver = 'adam', learning_rate = 'adaptive', tol = 1e-9)
grid = GridSearchCV(estimator = model, param_grid = parameters, verbose = 3)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
features = X_train.shape[1]
parameters = {'hidden_layer_sizes':[(1),(features),
(features,features), (features,features,features),
(features,features,features,features),
(features,features,features,features,features)]}
model = MLPClassifier(random_state = 1,max_iter = 1000,
solver = 'adam', learning_rate = 'adaptive', tol = 1e-9)
grid = GridSearchCV(estimator = model, param_grid = parameters, verbose = 3)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
features = X_train.shape[1]
parameters = {'hidden_layer_sizes':[(1),(features),
(features,features), (features,features,features),
(features,features,features,features),
(features,features,features,features,features)]}
model = MLPClassifier(random_state = 1,max_iter = 1000,
solver = 'adam', learning_rate = 'adaptive', tol = 1e-9)
grid = GridSearchCV(estimator = model, param_grid = parameters, verbose = 3)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
features = X_train.shape[1]
parameters = {'hidden_layer_sizes':[(1),(features),
(features,features), (features,features,features),
(features,features,features,features),
(features,features,features,features,features)]}
model = MLPClassifier(random_state = 1,max_iter = 1000,
solver = 'adam', learning_rate = 'adaptive', tol = 1e-9)
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 1000,
solver = 'adam', learning_rate = 'adaptive', tol = 1e-9)
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 1000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X, y)
grid.best_score_
grid.get_params
grid.n_jobs
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, verbose = 1)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, verbose = 2)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, n_jobs=-1, cv=3)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X, y)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X, y)
grid.best_score_
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
y = np.argmax(df[predictors].values, axis =1) + 1
X = df.drop(predictors, axis = 1)
sc = StnadardSCaler()
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
y = np.argmax(df[predictors].values, axis =1) + 1
X = df.drop(predictors, axis = 1)
sc = StandardSCaler()
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
sc = StandardScaler()
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
y = np.argmax(df[predictors].values, axis =1) + 1
X = df.drop(predictors, axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
sc = StandardScaler()
scaler = sc.fit(X_train)
X_train_sc = scaler.transform(X_train)
X_test_sc = scaler.transform(X_test)
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train_sc, y_train)
grid.best_score
grid.best_score_
grid.best_estimator_
grid.classes_
grid.best_index_
grid.best_params_
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
y = np.argmax(df[predictors].values, axis =1)
X = df.drop(predictors, axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
scaler = sc.fit(X_train)
X_train_sc = scaler.transform(X_train)
X_test_sc = scaler.transform(X_test)
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train_sc, y_train)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100), (100,100,100,100,100,100), (100,100,100,100,100,100, 100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
scaler = sc.fit(X_train)
X_train_sc = scaler.transform(X_train)
X_test_sc = scaler.transform(X_test)
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100), (100,100,100,100), (100,100,100,100,100), (100,100,100,100,100,100), (100,100,100,100,100,100, 100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train_sc, y_train)
grid.best_score_
grid.best_estimator_
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train, y_train)
grid.best_score_
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
y = np.argmax(df[predictors].values, axis =1)
X = df.drop(predictors, axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X_train, y_train)
grid.best_score_
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
scaler = sc.fit(X_train)
X_train_sc = scaler.transform(X_train)
X_test_sc = scaler.transform(X_test)
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train_sc, y_train)
grid.best_score_
grid.score(X_test_sc, y_test)
blogdown:::preview_site()
View(train_test_split)
quit
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE)
library(blogdown)
serve_site()
reticulate::repl_python()
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X_train, y_train)
print(grid.best_score_)
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X_train, y_train)
print(grid.best_score_)
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X_train, y_train)
print(grid.best_score_)
quit
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE)
stop_server()
blogdown:::preview_site()
stop_server()
blogdown:::preview_site()
stop_server()
blogdown:::preview_site()
serve_site()
blogdown:::preview_site()
library(blogdown)
serve_site()
blogdown:::preview_site()
reticulate::repl_python()
```{python data}
```{python data}
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X_train, y_train)
print(grid.best_score_)
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv('https://www.openml.org/data/get_csv/1592296/php9xWOpn')
predictors = ['V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'Class']
df['Class'] -= 1
y = np.argmax(df[predictors].values, axis =1)
X = df.drop(predictors, axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters)
grid.fit(X_train, y_train)
print(grid.best_score_)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
scaler = sc.fit(X_train)
X_train_sc = scaler.transform(X_train)
X_test_sc = scaler.transform(X_test)
parameters = {'hidden_layer_sizes':[(1),(100), (100,100), (100,100,100),
(100,100,100,100),
(100,100,100,100,100),
(100,100,100,100,100,100),
(100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100),
(100,100,100,100,100,100,100,100,100,100)]}
model = MLPClassifier(random_state = 1,max_iter = 10000,
solver = 'adam', learning_rate = 'adaptive')
grid = GridSearchCV(estimator = model, param_grid = parameters, cv=3)
grid.fit(X_train_sc, y_train)
grid.best_score_
grid.score(X_test_sc, y_test)
library(blogdown)
serve_site()
install.packages("appsilon")
blogdown:::new_post_addin()
install.packages("dlstats")
library(dlstats)
?dlstats
dlstats::bioc_stats()
devtools::install_github("metacran/cranlogs")
library(devtools)
install.packages("devtools")
devtools::install_github("metacran/cranlogs")
library(cranlogs)
library(cranlogs)
install.packages("cranlogs")
library(cranlogs)
remove.packages("cranlogs", lib="~/R/win-library/4.1")
blogdown:::preview_site()
library(cranlogs)
top100 <- cran_top_downloads(when = 'last-month', count = 100)
library(tidyverse)
library(tidyverse)
library(cranlogs)
top100 <- cran_top_downloads(when = 'last-month', count = 100)
top100 %>% head()
mine <- installed.packages()
mine
mine <- installed.packages() %>%
select(package)
mine <- installed.packages() %>%
data.frame() %>%
select(package)
mine <- installed.packages() %>%
data.frame()
View(mine)
mine <- installed.packages() %>%
data.frame() %>%
select(Package)
View(mine)
?cran_top_downloads
mine <- installed.packages() %>%
data.frame() %>%
select(Package)
top100 %>%
filter(!Package %in% mine$Package)
top100 %>%
filter(!package %in% mine$Package)
new <- top100 %>%
filter(!package %in% mine$Package)
View(new)
library(tidyverse)
library(cranlogs)
top100 <- cran_top_downloads(when = 'last-month', count = 100)
top100 %>% head()
?rlang
?glue
cli
?clip
?cli
mine <- installed.packages() %>%
data.frame() %>%
select(Package)
new <- top100 %>%
filter(!package %in% mine$Package)
new
new$package %>%
cran_downloads(when = "last-month")
new$package %>%
cran_downloads(when = "last-month") %>%
ggplot(aes(x = date, y = count, color = package)) +
geom_line()
View(new)
blogdown:::preview_site()
