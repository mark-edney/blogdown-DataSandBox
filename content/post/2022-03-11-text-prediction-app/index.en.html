---
title: Text Prediction Shiny App pt 1
author: Mark Edney
date: '2022-05-31'
slug: []
categories:
  - Project
tags:
  - Shiny App
  - NLP
  - R
draft: no
description: 'A predictive Text Shiny Application'
image: "/img/predict_text.jpg"
archives:
  - 2022/05
latex: true
---



<blockquote>
<p>This Shiny App was first written in May of 2021</p>
</blockquote>
<div id="description" class="section level2">
<h2>Description</h2>
<p>The goal of this project was to create a N-gram based model to predict the word to follow the users input. This project was to complete the Capstone project for the Johns Hopkins University Data science program on coursera. The data for this project was provided by swiftkey.</p>
<p>This project will be broken down to multiple parts as the entire project is quite large. This first part will deal with the creation of the corpus. This corpus will require additional filtering to remove words that are not English, contractions and words that are considered profanity.</p>
</div>
<div id="initialization" class="section level2">
<h2>Initialization</h2>
<p>The initial step that loads the required libraries and downloads the data sets if not all read on file.</p>
<pre class="r"><code>library(tidyverse)
library(tidytext)
library(pryr)

#downloads the corpus files, profanity filter and English dictionary

url &lt;- &quot;https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip&quot;
url2 &lt;- &quot;https://www.freewebheaders.com/download/files/facebook-bad-words-list_comma-separated-text-file_2021_01_18.zip&quot;
url3 &lt;- &quot;https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt&quot;
url4 &lt;- &quot;https://raw.githubusercontent.com/mark-edney/Capestone/1c143b40dd71f0564c3248df2a8638d08af10440/data/contractions.txt&quot;

# I have added this if statement for testing, if the files are found than they will not be downloaded again
if(dir.exists(&quot;~/R/Capestone/data/&quot;) == FALSE){
       dir.create(&quot;~/R/Capestone/data/&quot;)}

if(file.exists(&quot;~/R/Capestone/data/data.zip&quot;) == FALSE|
   file.exists(&quot;~/R/Capestone/data/prof.zip&quot;)==FALSE|
   file.exists(&quot;~/R/Capestone/data/diction.txt&quot;)==FALSE|
    file.exists(&quot;~/R/Capestone/data/contractions.txt&quot;)==FALSE){
        download.file(url,destfile = &quot;~/R/Capestone/data/data.zip&quot;)
        download.file(url2,destfile = &quot;~/R/Capestone/data/prof.zip&quot;)
        download.file(url3,destfile = &quot;~/R/Capestone/data/diction.txt&quot;)
        download.file(url4,destfile = &quot;~/R/Capestone/data/contractions.txt&quot;)
        setwd(&quot;~/R/Capestone/data/&quot;)
        unzip(&quot;~/R/Capestone/data/prof.zip&quot;)
        unzip(&quot;~/R/Capestone/data/data.zip&quot;)
        setwd(&quot;~/R/Capestone&quot;)
}</code></pre>
</div>
<div id="creating-a-corpus" class="section level2">
<h2>Creating a Corpus</h2>
<p>The project requires a Corpus, or a large body of text to create models. At this stage, the files are opened and joined. The Corpus is so large and requires so much ram that a sample of 10% is taken.</p>
<pre class="r"><code>blog &lt;- read_lines(&quot;~/R/Capestone/data/final/en_US/en_US.blogs.txt&quot;)
news &lt;- read_lines(&quot;~/R/Capestone/data/final/en_US/en_US.news.txt&quot;)
twitter &lt;- read_lines(&quot;~/R/Capestone/data/final/en_US/en_US.twitter.txt&quot;)
blog &lt;- tibble(text = blog) 
news &lt;- tibble(text = news)
twitter &lt;- tibble(text = twitter)

set.seed(90210)
corpus &lt;- bind_rows(blog,twitter,news) %&gt;% 
        slice_sample(prop = 0.10) %&gt;%
        mutate(line = row_number())</code></pre>
</div>
<div id="corpus-filtering" class="section level2">
<h2>Corpus filtering</h2>
<p>Here the corpus filter is created to remove profanity and any word that is not in the English dictionary.</p>
<pre class="r"><code>prof &lt;- read_lines(&quot;~/R/Capestone/data/facebook-bad-words-list_comma-separated-text-file_2021_01_18.txt&quot;)[15]
prof &lt;- prof %&gt;% 
        str_split(&quot;, &quot;) %&gt;% 
        flatten() %&gt;% 
        unlist()
prof &lt;- tibble(&quot;word&quot; = prof)

english &lt;- read_lines(&quot;~/R/Capestone/data/diction.txt&quot;)
english &lt;- tibble(&quot;word&quot; = english[!english==&quot;&quot;])

contract &lt;- read_lines(&quot;~/R/Capestone/data/contractions.txt&quot;)
contract &lt;- tibble(&quot;word&quot; = contract) %&gt;% unnest_tokens(word,word)</code></pre>
</div>
<div id="vocabulary" class="section level2">
<h2>Vocabulary</h2>
<p>A vocabulary of words is created from the unique words with the applied filters.</p>
<pre class="r"><code>#clean up ram
rm(blog,news,twitter)
voc &lt;- bind_rows(english, contract) %&gt;% anti_join(prof)

unigram &lt;- corpus %&gt;% unnest_tokens(ngram, text, token = &quot;ngrams&quot;, n = 1) %&gt;%
        semi_join(voc, by = c(&quot;ngram&quot;=&quot;word&quot;)) 
#decreases the voc size
voc &lt;- tibble(word = unique(unigram$ngram))</code></pre>
</div>
<div id="corpus-exploratoin" class="section level2">
<h2>Corpus Exploratoin</h2>
<p>Now that the corpus is created, we can do some exploration into the text.</p>
<pre class="r"><code>corpus %&gt;% 
        head()</code></pre>
<pre><code>## # A tibble: 6 x 2
##   text                                                                      line
##   &lt;chr&gt;                                                                    &lt;int&gt;
## 1 no we don&#39;t just kidding yes we do d                                         1
## 2 it sounds like a man walking on snow but it&#39;s my heartbeat cara on how ~     2
## 3 they thought about it but you&#39;re too short                                   3
## 4 indeed dear to my heart want to go see                                       4
## 5 i know its a tough world out there the secret to succeeding isn&#39;t stepp~     5
## 6 we&#39;re wishing for the cure too good luck                                     6</code></pre>
</div>
<div id="vocabulary-exporation" class="section level2">
<h2>Vocabulary Exporation</h2>
<p>By using the arrange function, we can sort the unigrams by their counts. This provides some insight on which words come up the most frequently. It is not surprisingly that the most common word is “the”. These frequencies will play an important role in the test prediction so its important to consider them. It is very common to filter out “Stop Words” as the likely add little value to predictions.</p>
<pre class="r"><code>unigram %&gt;%
        arrange(desc(n)) %&gt;%
        head()</code></pre>
<pre><code>## # A tibble: 6 x 2
##   ngram      n
##   &lt;chr&gt;  &lt;int&gt;
## 1 the   476750
## 2 to    277081
## 3 and   242032
## 4 a     238301
## 5 of    201539
## 6 in    165645</code></pre>
<blockquote>
<p>Photo by <a href="https://unsplash.com/@sandym10?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Sandy Millar</a> on <a href="https://unsplash.com/s/photos/predictive-text?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
</blockquote>
</div>
