---
title: Benchmarking Data Tables
author: Mark Edney
date: '2022-04-08'
slug: []
categories:
  - How-to
tags:
  - R
draft: yes
description: ''
archives:
  - 2022/04
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p>When I started learning R, I was heard vague tales of the use of Data tables. Really just whisperers of something to consider in the future after I’ve become more proficient. Well now is the time to learn what if anything I’ve been missing out on.</p>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Data tables are a potenial replacement for the common dataframe. It seeks to perform that same role but with improved performance. I would like to see the speed comparision between dataframes, data tables and tibbles. I will use the microbenchmark package to perfoprm the actuall benchmarking.</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --</code></pre>
<pre><code>## v ggplot2 3.3.5     v purrr   0.3.4
## v tibble  3.1.6     v dplyr   1.0.8
## v tidyr   1.2.0     v stringr 1.4.0
## v readr   2.1.2     v forcats 0.5.1</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(data.table)</code></pre>
<pre><code>## 
## Attaching package: &#39;data.table&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     between, first, last</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     transpose</code></pre>
<pre class="r"><code>library(microbenchmark)
library(farff)</code></pre>
<p>For the benchmark, I will use the ‘credit-g’ dataset which can be found on the <a href="https://www.openml.org/search?type=data&amp;status=active&amp;id=31">open ml</a> website. I’m pretty sure the last openml dataset I used was a csv file but the seem to have moved to a ARFF format. I will need to use the <code>farff</code> package to load the data.</p>
<pre class="r"><code>df &lt;- farff::readARFF(&#39;dataset_31_credit-g.arff&#39;)</code></pre>
<pre><code>## Parse with reader=readr : dataset_31_credit-g.arff</code></pre>
<pre><code>## header: 0.110000; preproc: 0.000000; data: 0.290000; postproc: 0.000000; total: 0.400000</code></pre>
<pre class="r"><code>dt &lt;- setDT(df)
ti &lt;- tibble(df)</code></pre>
</div>
<div id="syntax" class="section level2">
<h2>Syntax</h2>
<p>The syntax for data tables is a little be different</p>
<blockquote>
<p>DT[i,j,by]</p>
</blockquote>
<p>In this manner, a at data table can be subset by i, to calculate j when grouped with a by. For this comparison, we will look at the performance of finding the average age of the credit holders grouped by the class or credit rating.</p>
<p>Along with the special syntax, there are some common functions that add some additional simpilifcation.</p>
<blockquote>
<p>.()
The ‘.()’ function can be used as a place holder for ‘list()’. The list function is usefull for subsetti</p>
</blockquote>
</div>
<div id="grouped-aggreagate" class="section level2">
<h2>Grouped Aggreagate</h2>
<pre class="r"><code>microbenchmark(df %&gt;% 
                                 group_by(class) %&gt;%
                       summarise(avg = mean(age)),
               dt[,.(avg = mean(age)), by = class],
               ti %&gt;% 
                       group_by(class) %&gt;%
                       summarise(avg = mean(age)))</code></pre>
<pre><code>## Unit: microseconds
##                                                   expr      min        lq
##  df %&gt;% group_by(class) %&gt;% summarise(avg = mean(age)) 9318.700 10287.101
##                   dt[, .(avg = mean(age)), by = class]  922.500  1349.952
##  ti %&gt;% group_by(class) %&gt;% summarise(avg = mean(age)) 9557.101 10444.852
##       mean    median        uq     max neval
##  11469.692 10857.901 12011.151 23037.3   100
##   1649.708  1499.001  1754.351 11299.3   100
##  11878.452 11061.951 12124.501 33562.7   100</code></pre>
</div>
