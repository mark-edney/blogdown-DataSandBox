---
title: Webscraping in R with Rvest
author: Mark Edney
date: '2022-06-22'
slug: []
categories:
  - How-to
  - Projects
tags:
  - NLP
  - R
draft: no
description: 'A tutorial on the Rvest package in R'
image: "img/harvest.jpg"
archives:
  - 2022/06
---
Web scraping has become an incredibly important tool in data science, as an easy way to generate new data. The main advantage is the automation of some pretty repetitive tasks. Web scrapping can also be a good way of keeping up with new data on a website, assuming it doesn't have a big change in its html structure.  

## Introduction 
This project is inspired from a Youtube video created by [Thu Vu](https://www.youtube.com/watch?v=RuNolAh_4bU) about at data scraping project about the Witcher books series. Her project utilizes `python` and the `Selenium`. I love the book series and I loved the project idea. I've also had it on my backlog to learn the `Rvest` library for a while so it seems like a great opportunity combine these two interests.

Rather than completing the project on the Witcher series, I thought it would be interesting to explore another book series that I love in the **Stormlight Archive** by Brandon Sanderson. If you are not familiar with the series, it is an epic fantasy story sprawling over four main books at the time of the publishing of this post. Sanderson is a fantastic author and I feel that the **Stormlight Archive** is his best work. 

For this project, I will scrap the Coppermind website for all of the character names in the series. The Coppermind is a fan made Wiki site that covers the work of Brandon Sanderson. After retrieving all of the character names, I will create a graph outlining the relationships between each character. This work will be done in a future post, so please look forward to it. 

## Inializaton
The first step is to download the `Rvest` library. This is done with the following code.
```{r install, eval=FALSE}
install.packages("rvest")
```
The `rvest` package is also installed if you have the `tidyverse` package installed. Loading the `tidyverse` package however will not load the `rvest` package, so they both need to be loaded separately. 

```{r load, warning=FALSE,message=FALSE}
library("tidyverse")
library("rvest")
```

## Datascraping
To start the data scraping exercise, we need to save the url of the website we would like to scrape. This is the url for the character page for the Stromlight Archives series.  
```{r webload}
site <- read_html("https://coppermind.net/wiki/Category:Rosharans")
```
While on the website in your own browser, you right click on the specific element your interested in scrapping and select inspect. This is at least the method used for Firefox, but it should be similar to other browsers.

From here you have to do a little digging and a little experimentation to determine which html elements are important for the character list. It is pretty useful to have a strong understanding of html at this point. From my experimentation, I found that the list was contained within a div with the class "mw-category-group". A div is a generic divider tag in html and can represent many different things. I selected the elements with the following code:
```{r div}
names <- site %>% 
        html_elements("div.mw-category-group")
```
You use the `html_elements` command to select the all the elements for a specific html tag you pass. The addition of the ".mw-category-group", specifies the selection to only divs with the specific `class`. The `class` is an attribute of the html tags, used to identify and group html elements together. I have found that this notation is the best way to filter elements. 

Within the div elements, there is a further sub-structure for an element in the character list. The characters are contained within an `<li>` tag as a list item and as an `<a>` tag as a hyperlink within that list item. We can explore further into the html structure by selecting these elements. After the final structure is selected, we can use the `html_attr` function to return a attribute of the selected elements. The 'title' attribute stores the character name in the html. We could also the `html_text2` function to return the text of the hyperlink but I've found that the 'title' attribute is better structured.     

```{r elements}
names <- names %>%
        html_elements("li") %>%
        html_elements("a") %>%
        html_attr("title")
```
## Data Cleaning

We can start exploring the results of the scrapping
```{r test2}
print(head(names))
```
Oops, the program has captured an additional list that precedes the character list. Through my testing, I have not found a way to distinguish between the two lists from the html structure. Thankfully we can rely on Regular Expressions to complete the job. The unwanted list items all start with "Category:", so with a single expression of the `str_starts` from the `stringr` package we can remove these elements.

```{r regex1}
names <- names[!str_starts(names, "Category:")]
```
The list still requires some additional work as there are "()" used throughout the list to give additional context. These "()" will not appear in the text so we need to remove them with a second Regular Expression. Although it is not clear to me, the "(" needs to be double escaped with two "\\" rather the just one. 
```{r regex2}
names <- str_remove_all(names," \\(.*\\)")

print(head(names, 10))
```
We can see that the scrapped data is in much better condition. There is still additional work we can do as the names will sometimes include first and last names. The last names are not particularly important so we can drop them alltogether. 

```{r regex3}
names <- str_remove_all(names," .*") 

print(head(names, 10))
```

Now we can see that the final list is in condition that we can use to better explore the relationships. 

## Conclusion
We have scraped the **Stormlight Archive** character wiki website with the `rvest` package. We loaded the website with `read_html` function. We were than able to sort through the different html elements with the `html_elements` to find the were the character list is stored. We than obtained the actual names with the `html_attr` function. The data collected still contained some unwanted data. We were able to remove an additional list, data in parenthesis and the last names of all characters. We can now move forward with scrapping the books to identify the strength of relationships between each characters. 

```{=html}
Photo by <a href="https://unsplash.com/@pazarando?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Paz Arando</a> on <a href="https://unsplash.com/s/photos/harvest?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
```  